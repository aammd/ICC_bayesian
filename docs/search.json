{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2022-06-03T11:58:20-04:00"
    },
    {
      "path": "index.html",
      "title": "Bayesian version of the Interclass Correlation Coefficient (ICC)",
      "description": "How much do groups contribute to variance in a response? Using posterior simulations to get a simple (?) answer.\n",
      "author": [],
      "contents": "\nHow much variation is contributed by group differences? This is a useful question in several contexts. Sometimes it is simply a guide to model building – is it “worth it” to include group effects in my model? In other projects we might care about measuring variation explicitly. For example, we might want to measure what proportion of phenotypic variation can be ascribed to different genotypes. Or we might have different experimental subjects, and we want to know if the same subject responds in the same way across trials.\nClearly, observations from the same subject will be correlated to each other, since all those observations come from the same person/animal/thing, which differs in all kinds of unmeasured ways from the other people/animal/things we are studying. This correlation is measured, for some models, using the “interclass correlation coefficient” (ICC). The trouble is that the ICC:\nDoesn’t have any uncertainty estimates – since it comes from a model, we have to represent a distribution of possible correlations consistent with the data\nOnly works sometimes. There are only a few models for which there are formulae to calculate ICC, and a wide class of flexible models are left out with no clear way to proceed.\nHere I’m suggesting an approach to calculate the ICC based on a Bayesian posterior distribution for the model coefficients. The approach is heavily based on the Bayesian R2 (Gelman et al. 2019). The approach I’m suggesting replaces a single value of ICC with a distribution. However, for models beyond simple intercept-only models, this ICC calculation produces a curve, \\(\\text{ICC}(x)\\) because in these cases the contribution of group effects depends on the rest of the model.\nBelow is a quick description of what I’m suggesting followed by some simulations testing it in a few interesting cases.\nWhat is the ICC\nThe formula goes like this:\n\\[\n\\frac{\\sigma_{group}^2}{\\sigma_{group}^2 + \\sigma_{obs}^2}\n\\]\nWhich works for a model like this:\n\\[\n\\begin{align}\ny_i &\\sim \\text{Normal}(\\mu_i, \\sigma_{obs}^2) \\\\\n\\mu_i &= \\alpha_0 + X_i\\beta+ \\alpha_{\\text{group}[i]} \\\\\n\\alpha_{\\text{group}} &\\sim \\text{Normal}(0, \\sigma_{\\text{group}}^2)\n\\end{align}\n\\]\nThat is, a gaussian response with random intercepts for groups. In this case, \\(X_i\\beta\\) could be any vector of predictors, multiplied by their coefficients.\n\n\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(lme4)\nlibrary(rptR)\nlibrary(brms)\nlibrary(tidyverse)\nlibrary(tidybayes)\n\n\n\nGaussian Intercept-only model\nThis is the classic case: a regression of a gaussian species across\n\n\nwater <- runif(50)\n\navg_size <- 23\n\necart_size <- rnorm(20, mean = 0, sd = 3)\n\nslope_water <- 4.2\n\navg_resp <- expand_grid(sp_id = 1:20,\n            water) |>\n  mutate(avg = avg_size + ecart_size[sp_id] + slope_water*water)\n\navg_resp |>\n  ggplot(aes(x = water, y = avg, group = sp_id)) +\n  geom_line()\n\n\n\nobs_sd <- 2\n\nobs_data <- avg_resp |>\n  mutate(obs = rnorm(length(avg), mean = avg, sd = obs_sd))\n\nobs_data |>\n  ggplot(aes(x = water, y = obs)) + geom_point() +\n  geom_line(aes(y = avg, group = sp_id))\n\n\n\nlmer_mod <- lmer(obs~water + (1 | sp_id), data = obs_data)\n\ngauss_vc <- VarCorr(lmer_mod) |> as.data.frame()\ngauss_vc$sdcor[[1]]^2\n\n\n[1] 8.181097\n\n# 2.4490^2/(2.4490^2 + 0.29936^2)\nfreq_line <- gauss_vc$vcov[[1]]/(gauss_vc$vcov[[1]] + gauss_vc$vcov[[2]])\n\n\nrpt_obs <- rpt(obs ~ water + (1 | sp_id),\n                     data = mutate(obs_data, sp_id = factor(sp_id)),\n          grname = \"sp_id\", datatype = \"Gaussian\", nboot = 0, npermut = 0)\n\nrpt_obs\n\n\n\n\nRepeatability estimation using the lmm method \n\nRepeatability for sp_id\nR  = 0.664\nSE =  NA \nCI = [NA, NA]\nP  = 3.74e-212 [LRT]\n     NA [Permutation]\n\n### bayes\n\n\n\ngaussian_intercept_bf <- bf(obs~ water + (1 | sp_id),\n                            family = gaussian())\n\nget_prior(gaussian_intercept_bf,\n          data = obs_data)\n\n\n                   prior     class      coef group resp dpar nlpar\n                  (flat)         b                                \n                  (flat)         b     water                      \n student_t(3, 23.7, 3.5) Intercept                                \n    student_t(3, 0, 3.5)        sd                                \n    student_t(3, 0, 3.5)        sd           sp_id                \n    student_t(3, 0, 3.5)        sd Intercept sp_id                \n    student_t(3, 0, 3.5)     sigma                                \n bound       source\n            default\n       (vectorized)\n            default\n            default\n       (vectorized)\n       (vectorized)\n            default\n\ngaussian_intercept_priors <- c(\n  prior(exponential(.3), class = sigma),\n  prior(exponential(.2), class = \"sd\"),\n  prior(normal(5, 6), class = \"b\"),\n  prior(normal(50, 10), class = \"Intercept\")\n)\n\n\ngaussian_brm <- brm(gaussian_intercept_bf,\n                 prior = gaussian_intercept_priors,\n                 data = obs_data, file = \"gaussian_brm\",\n                 backend = \"cmdstanr\", cores = 4)\n\ngaussian_brm <- update(gaussian_brm, newdata = obs_data, cores = 4, refresh = 0)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 2 finished in 7.8 seconds.\nChain 4 finished in 8.4 seconds.\nChain 1 finished in 9.7 seconds.\nChain 3 finished in 10.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 9.1 seconds.\nTotal execution time: 10.7 seconds.\n\nbrms::bayes_R2(gaussian_brm)\n\n\n    Estimate   Est.Error      Q2.5     Q97.5\nR2 0.6837725 0.009507782 0.6642681 0.7014138\n\nsample_draws <- expand_grid(sp_id = letters,\n                            water = unique(obs_data$water)) |>\n  add_epred_draws(gaussian_brm,\n                  allow_new_levels = TRUE,\n                  sample_new_levels= \"gaussian\")\n\nsample_variance <- sample_draws |>\n  ungroup() |>\n  nest_by(.draw, water) |>\n  mutate(Vpred = var(data$.epred))\n\nsigma_draws <- spread_draws(gaussian_brm, sigma)\n\nicc_of_x <- sample_variance |>\n  ungroup() |>\n  left_join(sigma_draws, by = \".draw\") |>\n  mutate(icc_x = Vpred/(Vpred + sigma^2))\n\nicc_of_x |>\n  select(.draw, icc_x) |> distinct() |>\n  ggplot(aes(x = icc_x)) +\n  geom_histogram() +\n  geom_vline(xintercept = freq_line, col = \"lightblue\")\n\n\n\n\nThere are many elaborations suggested by (Nakagawa and Schielzeth 2010)\n\n\n\nGelman, Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. 2019. “R-Squared for Bayesian Regression Models.” The American Statistician 73 (3): 307–9. https://doi.org/10.1080/00031305.2018.1549100.\n\n\nNakagawa, Shinichi, and Holger Schielzeth. 2010. “Repeatability for Gaussian and Non-Gaussian Data: A Practical Guide for Biologists.” Biological Reviews 85 (4): 935–56. https://doi.org/10.1111/j.1469-185X.2010.00141.x.\n\n\n\n\n",
      "last_modified": "2022-06-03T11:59:20-04:00"
    }
  ],
  "collections": []
}
